{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LLM-Powered Word Sense Disambiguation\n",
        "\n",
        "This notebook helps you automatically identify the correct **WordNet sense** (synset) for ambiguous words in context using Large Language Models.\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Getting Started\n",
        "\n",
        "### Step 1: Save Your Own Copy\n",
        "\n",
        "**Important!** You're viewing a shared notebook. To run it and save your work:\n",
        "\n",
        "1. Click **File** ‚Üí **Save a copy in Drive**\n",
        "2. A new tab will open with your personal copy\n",
        "3. You can now edit, run cells, and your changes will be saved automatically\n",
        "\n",
        "> üí° **Tip:** Rename your copy (click the title at the top) to something memorable like \"WSD Annotation - My Project\"\n",
        "\n",
        "### Step 2: Connect to a Runtime\n",
        "\n",
        "Before running any code, you need to connect to Google's servers:\n",
        "\n",
        "1. Click **Connect** in the top-right corner (or **Runtime** ‚Üí **Connect**)\n",
        "2. Wait for the green checkmark ‚úì\n",
        "3. You now have access to a virtual machine that will run your code\n",
        "\n",
        "> ‚ö†Ô∏è **Note:** Free Colab sessions disconnect after ~90 minutes of inactivity. Your saved notebook won't be lost, but you'll need to re-run cells from the beginning.\n",
        "\n",
        "---\n",
        "\n",
        "## üìã What This Notebook Does\n",
        "\n",
        "1. **Takes your input**: A word, its sentence context, and candidate senses\n",
        "2. **Queries an LLM**: Sends the disambiguation task to a language model\n",
        "3. **Returns the answer**: The model selects the most appropriate WordNet synset\n",
        "4. **Evaluates results**: If you provide ground truth labels, calculates accuracy\n",
        "\n",
        "### Example Task\n",
        "\n",
        "| Component | Example |\n",
        "|-----------|---------|\n",
        "| **Word** | *bank* |\n",
        "| **Context** | \"She walked along the river bank at sunset.\" |\n",
        "| **Candidates** | `08420278-n` (financial institution), `09213565-n` (sloping land) |\n",
        "| **Model Output** | `09213565-n` ‚úì |\n",
        "\n",
        "---\n",
        "\n",
        "## üîß Requirements\n",
        "\n",
        "- A Google account (for Colab)\n",
        "- An API key from your chosen provider (OpenAI, DeepSeek, OpenRouter, etc.)\n",
        "- Your annotation data (words, contexts, and candidate synsets)\n",
        "\n",
        "Let's get started! Run each cell in order by clicking the ‚ñ∂Ô∏è play button or pressing `Shift+Enter`."
      ],
      "metadata": {
        "id": "g3YWLi3KUmyZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 1Ô∏è‚É£ Setup & Installation\n",
        "\n",
        "Run this cell to install required libraries and download WordNet data. This may take 1-2 minutes."
      ],
      "metadata": {
        "id": "7ToWWs_jUqzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üîß Install Libraries & Download WordNet { display-mode: \"form\" }\n",
        "#@markdown Click the ‚ñ∂Ô∏è button to run this cell. You only need to do this once per session.\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"üì¶ Installing required libraries...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"wn\", \"openai\"])\n",
        "\n",
        "print(\"üìö Downloading Open English WordNet (this may take a moment)...\")\n",
        "import wn\n",
        "try:\n",
        "    wn.download(\"oewn:2024\")\n",
        "except wn.Error:\n",
        "    print(\"   WordNet already downloaded!\")\n",
        "\n",
        "print(\"\\n‚úÖ Setup complete!\")"
      ],
      "metadata": {
        "id": "hC542KmbUsRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08f9219e-a8d4-4514-d430-dbacb3983967"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Installing required libraries...\n",
            "üìö Downloading Open English WordNet (this may take a moment)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Download [##############################] (12912118/12912118 bytes) Complete\n",
            "Read [##############################] (1298444/1298444) \n",
            "\u001b[KAdded oewn:2024 (Open English Wordnet)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Setup complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 2Ô∏è‚É£ API Configuration\n",
        "\n",
        "### What is an API?\n",
        "\n",
        "An **API** (Application Programming Interface) is a way for programs to communicate with each other. In this notebook, we use APIs to send text to language models (like GPT-4 or Claude) and receive their responses.\n",
        "\n",
        "Think of it like ordering at a restaurant:\n",
        "- You (the notebook) send a request to the kitchen (the API)\n",
        "- The kitchen processes your order using their recipes (the model)\n",
        "- You receive your meal (the model's response)\n",
        "\n",
        "### What is an API Key?\n",
        "\n",
        "An **API key** is like a password that:\n",
        "- **Identifies you** to the service provider\n",
        "- **Tracks your usage** for billing purposes\n",
        "- **Keeps your requests secure**\n",
        "\n",
        "> üîí **Security Note:** Your API key is entered securely (hidden as you type) and stays only in your browser session. It's never saved to the notebook file or sent anywhere except to your chosen API provider.\n",
        "\n",
        "---\n",
        "\n",
        "### üîë How to Get an API Key\n",
        "\n",
        "Choose your provider and follow the instructions:\n",
        "\n",
        "<details>\n",
        "<summary><b>OpenAI (GPT-4, GPT-4o, etc.)</b></summary>\n",
        "\n",
        "1. Go to [platform.openai.com](https://platform.openai.com/)\n",
        "2. Sign up or log in\n",
        "3. Click your profile icon ‚Üí **View API keys**\n",
        "4. Click **Create new secret key**\n",
        "5. Copy the key immediately (you won't see it again!)\n",
        "6. Add credits at **Billing** ‚Üí **Add payment method**\n",
        "\n",
        "**Cost:** ~$2.50‚Äì10 per 1M input tokens depending on model. For most WSD tasks, expect to spend pennies to a few dollars.\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary><b>DeepSeek</b></summary>\n",
        "\n",
        "1. Go to [platform.deepseek.com](https://platform.deepseek.com/)\n",
        "2. Sign up or log in\n",
        "3. Navigate to **API Keys** in your dashboard\n",
        "4. Create a new key and copy it\n",
        "\n",
        "**Cost:** Very affordable; check current pricing on their website.\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary><b>OpenRouter (access to many models)</b></summary>\n",
        "\n",
        "1. Go to [openrouter.ai](https://openrouter.ai/)\n",
        "2. Sign up or log in (you can use Google/GitHub)\n",
        "3. Go to **Keys** in the menu\n",
        "4. Click **Create Key**\n",
        "5. Copy your key\n",
        "\n",
        "**Benefit:** One API key gives you access to models from OpenAI, Anthropic, Google, Meta, Mistral, and more. Some models are even free!\n",
        "\n",
        "**Model names:** Use format like `openai/gpt-4o`, `anthropic/claude-3.5-sonnet`, `google/gemini-2.0-flash-exp:free`\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary><b>Custom / Self-hosted</b></summary>\n",
        "\n",
        "If you're running your own model server (e.g., with vLLM, Ollama, or text-generation-inference), enter your server's URL. The endpoint should be OpenAI-compatible.\n",
        "\n",
        "Example: `http://localhost:8000/v1` or `https://your-server.com/v1`\n",
        "\n",
        "</details>\n",
        "\n",
        "---\n",
        "\n",
        "### üí∞ How Much Will This Cost?\n",
        "\n",
        "API pricing is based on **tokens** (roughly 4 characters = 1 token). A typical WSD task might use:\n",
        "- ~200‚Äì500 tokens per annotation (depending on your prompt and candidate list)\n",
        "- 100 annotations ‚âà 20,000‚Äì50,000 tokens\n",
        "\n",
        "| Provider | Model | Approximate Cost for 100 Annotations |\n",
        "|----------|-------|--------------------------------------|\n",
        "| OpenAI | gpt-4o-mini | ~0.01‚Äì0.03 |\n",
        "| OpenAI | gpt-4o | ~0.05‚Äì0.15 |\n",
        "| DeepSeek | deepseek-chat | ~0.01‚Äì0.02 |\n",
        "| OpenRouter | Various free models | 0.00 |\n",
        "\n",
        "> üí° **Tip:** Start with a smaller batch (5‚Äì10 items) to test your setup before running large annotation jobs."
      ],
      "metadata": {
        "id": "OJZXG8CfUuqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üåê Select API Provider { display-mode: \"form\" }\n",
        "\n",
        "api_provider = \"DeepSeek\" #@param [\"OpenAI\", \"DeepSeek\", \"OpenRouter\", \"Custom\"]\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Custom Base URL** (only used if \"Custom\" is selected above):\n",
        "custom_base_url = \"https://api.example.com/v1\" #@param {type:\"string\"}\n",
        "\n",
        "# Define base URLs for each provider\n",
        "PROVIDER_URLS = {\n",
        "    \"OpenAI\": \"https://api.openai.com/v1\",\n",
        "    \"DeepSeek\": \"https://api.deepseek.com\",\n",
        "    \"OpenRouter\": \"https://openrouter.ai/api/v1\",\n",
        "}\n",
        "\n",
        "# Set the base URL\n",
        "if api_provider == \"Custom\":\n",
        "    BASE_URL = custom_base_url\n",
        "else:\n",
        "    BASE_URL = PROVIDER_URLS[api_provider]\n",
        "\n",
        "print(f\"üåê API Provider: {api_provider}\")\n",
        "print(f\"üîó Base URL: {BASE_URL}\")\n",
        "\n",
        "# Store for later use\n",
        "API_CONFIG = {\n",
        "    \"provider\": api_provider,\n",
        "    \"base_url\": BASE_URL\n",
        "}"
      ],
      "metadata": {
        "id": "39yolKFAXVu-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f6df140-558d-4e90-fad7-35dd98039c5f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåê API Provider: DeepSeek\n",
            "üîó Base URL: https://api.deepseek.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üîë Enter Your API Key { display-mode: \"form\" }\n",
        "#@markdown Your key stays private and is not stored anywhere.\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "# Determine which environment variable to use/check\n",
        "env_var_name = f\"{API_CONFIG['provider'].upper()}_API_KEY\"\n",
        "if API_CONFIG['provider'] == \"Custom\":\n",
        "    env_var_name = \"CUSTOM_API_KEY\"\n",
        "\n",
        "print(f\"üîê Configuring API key for {API_CONFIG['provider']}...\")\n",
        "\n",
        "# Check if already set\n",
        "if env_var_name in os.environ and os.environ[env_var_name]:\n",
        "    api_key = os.environ[env_var_name]\n",
        "    print(f\"‚úÖ Using existing {env_var_name}\")\n",
        "else:\n",
        "    api_key = getpass.getpass(f\"Enter your {API_CONFIG['provider']} API key: \")\n",
        "    os.environ[env_var_name] = api_key\n",
        "    print(f\"‚úÖ API key saved to {env_var_name} for this session!\")\n",
        "\n",
        "# Initialize the OpenAI client with the configured base URL\n",
        "client = OpenAI(\n",
        "    api_key=api_key,\n",
        "    base_url=API_CONFIG['base_url']\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Client initialized!\")\n",
        "print(f\"   Provider: {API_CONFIG['provider']}\")\n",
        "print(f\"   Base URL: {API_CONFIG['base_url']}\")"
      ],
      "metadata": {
        "id": "JgAOkesSUw-F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0368c995-3c80-4549-9cb2-d11cec36586c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîê Configuring API key for DeepSeek...\n",
            "Enter your DeepSeek API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "‚úÖ API key saved to DEEPSEEK_API_KEY for this session!\n",
            "\n",
            "‚úÖ Client initialized!\n",
            "   Provider: DeepSeek\n",
            "   Base URL: https://api.deepseek.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 3Ô∏è‚É£ Model Settings\n",
        "\n",
        "#### Temperature\n",
        "\n",
        "**Temperature** controls how \"creative\" or \"random\" the model's responses are:\n",
        "\n",
        "| Value | Behavior | Use For |\n",
        "|-------|----------|---------|\n",
        "| **0.0** | Deterministic ‚Äî same input gives same output | ‚úÖ Annotation tasks |\n",
        "| **0.3‚Äì0.7** | Balanced ‚Äî some variety | Creative writing |\n",
        "| **1.0+** | High randomness ‚Äî very creative | Brainstorming |\n",
        "\n",
        "For word sense disambiguation, we use **a low temperature** because we want consistent, reproducible results.\n",
        "\n",
        "#### Reasoning Effort (OpenAI only)\n",
        "\n",
        "For OpenAI's reasoning models, this controls how much \"thinking\" the model does:\n",
        "\n",
        "- **none** ‚Äî Standard mode (for non-reasoning models)\n",
        "- **low** ‚Äî Quick reasoning\n",
        "- **medium** ‚Äî Balanced\n",
        "- **high** ‚Äî Deep reasoning (slower, more expensive, potentially more accurate)\n",
        "\n",
        "#### Responses API vs Chat Completions\n",
        "\n",
        "- **Responses API** ‚Äî OpenAI's newer API format (supports reasoning models)\n",
        "- **Chat Completions** ‚Äî Standard format supported by most providers\n",
        "\n",
        "> üí° **Tip:** If you're using DeepSeek, OpenRouter, or a custom provider, uncheck \"Use Responses API\" to use the compatible Chat Completions format."
      ],
      "metadata": {
        "id": "1wBJAcxlU0Ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ‚öôÔ∏è Model Configuration { display-mode: \"form\" }\n",
        "\n",
        "#@markdown ### Select Model\n",
        "#@markdown Common models by provider:\n",
        "#@markdown - **OpenAI**: `gpt-5.2`, `gpt-5.2-mini`, `gpt-5.2-nano` `gpt-4o`, `gpt-4o-mini`, `gpt-4-turbo`, `gpt-3.5-turbo`\n",
        "#@markdown - **DeepSeek**: `deepseek-chat`, `deepseek-reasoner`\n",
        "#@markdown - **OpenRouter**: `openai/gpt-4o`, `anthropic/claude-3.5-sonnet`, `google/gemini-2.0-flash-exp:free`\n",
        "\n",
        "model_name = \"deepseek-chat\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Reasoning Effort\n",
        "#@markdown (Applies to OpenAI reasoning models; may be ignored by other providers)\n",
        "reasoning_effort = \"none\" #@param [\"none\", \"low\", \"medium\", \"high\"]\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Temperature\n",
        "temperature = 0.0 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Use Responses API\n",
        "#@markdown Uncheck for providers that only support Chat Completions API\n",
        "use_responses_api = False #@param {type:\"boolean\"}\n",
        "\n",
        "# Store settings\n",
        "MODEL_CONFIG = {\n",
        "    \"model\": model_name,\n",
        "    \"reasoning_effort\": reasoning_effort,\n",
        "    \"use_responses_api\": use_responses_api\n",
        "}\n",
        "\n",
        "print(f\"üìä Model Configuration:\")\n",
        "print(f\"   ‚Ä¢ Provider: {API_CONFIG['provider']}\")\n",
        "print(f\"   ‚Ä¢ Model: {model_name}\")\n",
        "print(f\"   ‚Ä¢ Reasoning effort: {reasoning_effort}\")\n",
        "print(f\"   ‚Ä¢ API: {'Responses' if use_responses_api else 'Chat Completions'}\")\n",
        "print(\"\\n‚úÖ Settings saved!\")"
      ],
      "metadata": {
        "id": "3KMWVSgAU1wM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91ffc97a-a746-417d-c3b3-5e24ba9711fd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Model Configuration:\n",
            "   ‚Ä¢ Provider: DeepSeek\n",
            "   ‚Ä¢ Model: deepseek-chat\n",
            "   ‚Ä¢ Reasoning effort: none\n",
            "   ‚Ä¢ API: Chat Completions\n",
            "\n",
            "‚úÖ Settings saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 3Ô∏è‚É£ Custom System Prompt\n",
        "\n",
        "Customize the instructions given to the model. This prompt defines how the model should approach the word sense disambiguation task.\n",
        "\n",
        "The prompt can use these placeholders (automatically filled in for each task):\n",
        "- `{token}` ‚Äî The word to disambiguate\n",
        "- `{context}` ‚Äî The sentence containing the word  \n",
        "- `{synset_list}` ‚Äî Formatted list of candidate synsets with definitions\n",
        "\n",
        "**Tip:** You can use Markdown formatting in your prompt."
      ],
      "metadata": {
        "id": "4RLhhmExYKjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìù Configure System Prompt { display-mode: \"form\" }\n",
        "\n",
        "#@markdown ### System Instructions\n",
        "#@markdown These instructions set the model's role and behavior. Click on the leftmost arrow to see and modify them.\n",
        "\n",
        "system_prompt = \"\"\"You are an expert linguistic annotator specializing in word sense disambiguation (WSD). Your task is to identify the correct WordNet synset for a target word based on its context.\n",
        "\n",
        "## Your Approach\n",
        "\n",
        "1. **Read the context carefully** ‚Äî understand how the target word is being used\n",
        "2. **Consider each candidate synset** ‚Äî review the definition and example lemmas\n",
        "3. **Select the best match** ‚Äî choose the synset that most accurately captures the intended meaning\n",
        "\n",
        "## Important Guidelines\n",
        "\n",
        "- Focus on the **semantic meaning** in context, not just surface similarity\n",
        "- Consider **domain and register** ‚Äî is this technical, colloquial, figurative?\n",
        "- When multiple synsets seem plausible, choose the **most specific** one that fits\n",
        "- If the word is used **metaphorically**, consider whether a literal or figurative sense applies\n",
        "\n",
        "## Response Format\n",
        "\n",
        "Respond with **ONLY** the synset ID (e.g., `08420278-n`). Do not include any explanation, reasoning, or additional text.\"\"\"\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### User Prompt Template\n",
        "#@markdown This template is filled in for each annotation task. Use `{token}`, `{context}`, and `{synset_list}` as placeholders. Click on the leftmost arrow to see and modify the template.\n",
        "\n",
        "user_prompt_template = \"\"\"**TARGET WORD:** {token}\n",
        "\n",
        "**CONTEXT:** {context}\n",
        "\n",
        "**CANDIDATE SYNSETS:**\n",
        "{synset_list}\n",
        "\n",
        "Which synset ID best matches the meaning of \"{token}\" in the given context?\"\"\"\n",
        "\n",
        "# Store prompts\n",
        "PROMPT_CONFIG = {\n",
        "    \"system\": system_prompt,\n",
        "    \"user_template\": user_prompt_template\n",
        "}\n",
        "\n",
        "print(\"üìù Prompt Configuration Saved!\")\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"SYSTEM PROMPT PREVIEW:\")\n",
        "print(\"=\" * 70)\n",
        "print(system_prompt[:500] + \"...\" if len(system_prompt) > 500 else system_prompt)\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"USER PROMPT TEMPLATE PREVIEW:\")\n",
        "print(\"=\" * 70)\n",
        "print(user_prompt_template)"
      ],
      "metadata": {
        "id": "aSXNFGOhYQZl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24ade248-e213-4bc5-a3d8-5e4d78197e96"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìù Prompt Configuration Saved!\n",
            "\n",
            "======================================================================\n",
            "SYSTEM PROMPT PREVIEW:\n",
            "======================================================================\n",
            "You are an expert linguistic annotator specializing in word sense disambiguation (WSD). Your task is to identify the correct WordNet synset for a target word based on its context.\n",
            "\n",
            "## Your Approach\n",
            "\n",
            "1. **Read the context carefully** ‚Äî understand how the target word is being used\n",
            "2. **Consider each candidate synset** ‚Äî review the definition and example lemmas\n",
            "3. **Select the best match** ‚Äî choose the synset that most accurately captures the intended meaning\n",
            "\n",
            "## Important Guidelines\n",
            "\n",
            "- Focus on th...\n",
            "\n",
            "======================================================================\n",
            "USER PROMPT TEMPLATE PREVIEW:\n",
            "======================================================================\n",
            "**TARGET WORD:** {token}\n",
            "\n",
            "**CONTEXT:** {context}\n",
            "\n",
            "**CANDIDATE SYNSETS:**\n",
            "{synset_list}\n",
            "\n",
            "Which synset ID best matches the meaning of \"{token}\" in the given context?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 4Ô∏è‚É£ Input Your Data\n",
        "\n",
        "Choose how you want to enter your annotation data:\n",
        "\n",
        "- **Option A: Text Input** ‚Äî Type or paste directly (best for 1-10 items)\n",
        "- **Option B: File Upload** ‚Äî Upload a CSV or JSON file (best for larger datasets)"
      ],
      "metadata": {
        "id": "KHaf7h8iU4OZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìù Choose Input Method { display-mode: \"form\" }\n",
        "\n",
        "input_method = \"CSV Upload\" #@param [\"Text Input\", \"CSV Upload\", \"JSON Upload\"]\n",
        "\n",
        "print(f\"üìã Selected: {input_method}\")\n",
        "\n",
        "if input_method == \"Text Input\":\n",
        "    print(\"\\nüëá Run the next cell to enter your data in a text box.\")\n",
        "elif input_method == \"CSV Upload\":\n",
        "    print(\"\\nüëá Run the CSV upload cell below.\")\n",
        "else:\n",
        "    print(\"\\nüëá Run the JSON upload cell below.\")"
      ],
      "metadata": {
        "id": "H9xTiJ50U5QI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e768afc6-ac86-4aba-e941-3680ada9663d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìã Selected: CSV Upload\n",
            "\n",
            "üëá Run the CSV upload cell below.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Option A: Text Input\n",
        "\n",
        "Enter your data in the text box below using this format:\n",
        "\n",
        "token: bank  \n",
        "context: I walked along the river bank.  \n",
        "candidates: bank, shore, 08420278-n  \n",
        "ground_truth: 08420278-n\n",
        "\n",
        "token: run  \n",
        "context: The program will run overnight.  \n",
        "candidates: run, execute, operate\n",
        "\n",
        "**Field explanations:**\n",
        "- `token` ‚Äî The word to disambiguate\n",
        "- `context` ‚Äî The sentence containing the word\n",
        "- `candidates` ‚Äî Comma-separated list of lemmas (like `bank`) and/or synset offsets (like `08420278-n`)\n",
        "- `ground_truth` ‚Äî (Optional) The correct synset offset for evaluation\n",
        "\n",
        "Use `---` to separate multiple entries."
      ],
      "metadata": {
        "id": "KWhvKXASU75O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ‚úèÔ∏è Enter Your Data Here { display-mode: \"form\" }\n",
        "\n",
        "#@markdown Click on the leftmost arrow to show the code and paste your data in the text_input field. Follow thes format shown above.\n",
        "\n",
        "text_input = \"\"\"token: bank\n",
        "context: I deposited money at the bank this morning.\n",
        "candidates: bank, financial_institution, shore, river\n",
        "ground_truth: 08420278-n\n",
        "---\n",
        "token: bank\n",
        "context: We had a picnic on the river bank.\n",
        "candidates: bank, financial_institution, shore, slope\n",
        "ground_truth: 09213565-n\n",
        "---\n",
        "token: bright\n",
        "context: She is a bright student who excels in mathematics.\n",
        "candidates: bright, intelligent, luminous, shining\n",
        "\"\"\"\n",
        "\n",
        "# Parse the text input\n",
        "def parse_text_input(text):\n",
        "    \"\"\"Parse the structured text format into a list of annotation tasks.\"\"\"\n",
        "    entries = []\n",
        "    current_entry = {}\n",
        "\n",
        "    for line in text.strip().split('\\n'):\n",
        "        line = line.strip()\n",
        "\n",
        "        if line == '---':\n",
        "            if current_entry:\n",
        "                entries.append(current_entry)\n",
        "                current_entry = {}\n",
        "            continue\n",
        "\n",
        "        if ':' in line:\n",
        "            key, value = line.split(':', 1)\n",
        "            key = key.strip().lower()\n",
        "            value = value.strip()\n",
        "\n",
        "            if key == 'candidates':\n",
        "                # Split candidates and clean whitespace\n",
        "                value = [c.strip() for c in value.split(',')]\n",
        "\n",
        "            current_entry[key] = value\n",
        "\n",
        "    # Don't forget the last entry\n",
        "    if current_entry:\n",
        "        entries.append(current_entry)\n",
        "\n",
        "    return entries\n",
        "\n",
        "# Only process if Text Input was selected\n",
        "if input_method == \"Text Input\":\n",
        "    annotation_data = parse_text_input(text_input)\n",
        "    print(f\"‚úÖ Parsed {len(annotation_data)} annotation task(s):\\n\")\n",
        "\n",
        "    for i, entry in enumerate(annotation_data, 1):\n",
        "        print(f\"üìå Task {i}:\")\n",
        "        print(f\"   Token: {entry.get('token', '‚ùå MISSING')}\")\n",
        "        print(f\"   Context: {entry.get('context', '‚ùå MISSING')[:60]}...\")\n",
        "        print(f\"   Candidates: {entry.get('candidates', '‚ùå MISSING')}\")\n",
        "        if 'ground_truth' in entry:\n",
        "            print(f\"   Ground truth: {entry['ground_truth']}\")\n",
        "        print()\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è Skipping text input ‚Äî you selected file upload.\")\n",
        "    annotation_data = []"
      ],
      "metadata": {
        "id": "b143IlzFVI3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìÑ Upload CSV File { display-mode: \"form\" }\n",
        "#@markdown **CSV Format:** Your file should have these columns:\n",
        "#@markdown - `token` ‚Äî the word to annotate\n",
        "#@markdown - `context` ‚Äî the sentence\n",
        "#@markdown - `candidates` ‚Äî comma-separated lemmas/offsets (in one cell)\n",
        "#@markdown - `ground_truth` ‚Äî (optional) correct synset offset\n",
        "\n",
        "import csv\n",
        "import io\n",
        "\n",
        "if input_method == \"CSV Upload\":\n",
        "    from google.colab import files\n",
        "\n",
        "    print(\"üì§ Click 'Choose Files' to upload your CSV:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename, content in uploaded.items():\n",
        "        print(f\"\\nüìÇ Processing: {filename}\")\n",
        "        decoded = content.decode('utf-8')\n",
        "        reader = csv.DictReader(io.StringIO(decoded))\n",
        "\n",
        "        annotation_data = []\n",
        "        for row in reader:\n",
        "            entry = {\n",
        "                'token': row.get('token', '').strip(),\n",
        "                'context': row.get('context', '').strip(),\n",
        "                'candidates': [c.strip() for c in row.get('candidates', '').split(',')],\n",
        "            }\n",
        "            if row.get('ground_truth', '').strip():\n",
        "                entry['ground_truth'] = row['ground_truth'].strip()\n",
        "            annotation_data.append(entry)\n",
        "\n",
        "        print(f\"‚úÖ Loaded {len(annotation_data)} annotation task(s)\")\n",
        "        break  # Only process first file\n",
        "\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è Skipping CSV upload ‚Äî you selected a different input method.\")"
      ],
      "metadata": {
        "id": "_vU5fX1NVKN_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "7374b756-e2a6-46fb-b1c5-2c18e6099731"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì§ Click 'Choose Files' to upload your CSV:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f0d656b5-f49f-4ff4-b171-82e9a4eba7ea\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f0d656b5-f49f-4ff4-b171-82e9a4eba7ea\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving example_ground_truth.csv to example_ground_truth.csv\n",
            "\n",
            "üìÇ Processing: example_ground_truth.csv\n",
            "‚úÖ Loaded 4 annotation task(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìÑ Upload JSON File { display-mode: \"form\" }\n",
        "#@markdown **JSON Format:**\n",
        "#@markdown ```json\n",
        "#@markdown [\n",
        "#@markdown   {\n",
        "#@markdown     \"token\": \"bank\",\n",
        "#@markdown     \"context\": \"I walked along the river bank.\",\n",
        "#@markdown     \"candidates\": [\"bank\", \"shore\", \"08420278-n\"],\n",
        "#@markdown     \"ground_truth\": \"08420278-n\"\n",
        "#@markdown   }\n",
        "#@markdown ]\n",
        "#@markdown ```\n",
        "\n",
        "import json\n",
        "\n",
        "if input_method == \"JSON Upload\":\n",
        "    from google.colab import files\n",
        "\n",
        "    print(\"üì§ Click 'Choose Files' to upload your JSON:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename, content in uploaded.items():\n",
        "        print(f\"\\nüìÇ Processing: {filename}\")\n",
        "        annotation_data = json.loads(content.decode('utf-8'))\n",
        "        print(f\"‚úÖ Loaded {len(annotation_data)} annotation task(s)\")\n",
        "        break  # Only process first file\n",
        "\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è Skipping JSON upload ‚Äî you selected a different input method.\")"
      ],
      "metadata": {
        "id": "KW3_9PyxVLaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 5Ô∏è‚É£ Resolve Candidate Synsets\n",
        "\n",
        "This step expands your candidates into full WordNet synsets:\n",
        "- **Lemmas** (like `bank`) ‚Üí All matching synsets are retrieved\n",
        "- **Synset offsets** (like `08420278-n`) ‚Üí Looked up directly\n",
        "\n",
        "You'll see each synset's definition so you can verify the candidates make sense."
      ],
      "metadata": {
        "id": "wGJZ-Sw1VMlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üîç Resolve Synsets from Candidates { display-mode: \"form\" }\n",
        "\n",
        "import wn\n",
        "import re\n",
        "\n",
        "# Initialize English WordNet\n",
        "oewn = wn.Wordnet('oewn:2024')\n",
        "\n",
        "def is_synset_offset(s):\n",
        "    \"\"\"Check if string looks like a synset offset (e.g., '08420278-n').\"\"\"\n",
        "    return bool(re.match(r'^\\d{8}-[nvarsp]$', s))\n",
        "\n",
        "def resolve_candidates(candidates):\n",
        "    \"\"\"\n",
        "    Convert a list of lemmas and/or synset offsets into synset objects.\n",
        "    Returns a dict mapping synset IDs to synset info.\n",
        "    \"\"\"\n",
        "    resolved = {}\n",
        "\n",
        "    for candidate in candidates:\n",
        "        candidate = candidate.strip()\n",
        "\n",
        "        if is_synset_offset(candidate):\n",
        "            # It's a synset offset ‚Äî look it up directly\n",
        "            try:\n",
        "                # Construct the full synset ID for ewn\n",
        "                synset_id = f\"oewn-{candidate}\"\n",
        "                ss = wn.synset(synset_id)\n",
        "                resolved[candidate] = {\n",
        "                    'synset_id': candidate,\n",
        "                    'definition': ss.definition(),\n",
        "                    'lemmas': ss.lemmas(),\n",
        "                    'source': f\"offset:{candidate}\"\n",
        "                }\n",
        "            except wn.Error:\n",
        "                print(f\"   ‚ö†Ô∏è Could not find synset: {candidate}\")\n",
        "\n",
        "        else:\n",
        "            # It's a lemma ‚Äî find all synsets\n",
        "            synsets = oewn.synsets(candidate)\n",
        "            for ss in synsets:\n",
        "                # Extract offset from synset ID (e.g., 'ewn-08420278-n' ‚Üí '08420278-n')\n",
        "                offset = ss.id.replace('oewn-', '') # Changed ss.id() to ss.id\n",
        "                if offset not in resolved:\n",
        "                    resolved[offset] = {\n",
        "                        'synset_id': offset,\n",
        "                        'definition': ss.definition(),\n",
        "                        'lemmas': ss.lemmas(),\n",
        "                        'source': f\"lemma:{candidate}\"\n",
        "                    }\n",
        "\n",
        "    return resolved\n",
        "\n",
        "# Process all annotation tasks\n",
        "print(\"üîç Resolving synsets for all tasks...\\n\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for i, entry in enumerate(annotation_data, 1):\n",
        "    print(f\"\\nüìå Task {i}: '{entry['token']}' in \\\"{entry['context'][:50]}...\\\"\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    resolved = resolve_candidates(entry['candidates'])\n",
        "    entry['resolved_synsets'] = resolved\n",
        "\n",
        "    if not resolved:\n",
        "        print(\"   ‚ùå No synsets found! Check your candidates.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"   Found {len(resolved)} unique synset(s):\\n\")\n",
        "\n",
        "    for syn_id, info in resolved.items():\n",
        "        lemma_str = ', '.join(info['lemmas'][:5])\n",
        "        if len(info['lemmas']) > 5:\n",
        "            lemma_str += '...'\n",
        "        print(f\"   üîπ {syn_id}\")\n",
        "        print(f\"      Lemmas: {lemma_str}\")\n",
        "        print(f\"      Definition: {info['definition'][:80]}...\")\n",
        "        print()\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\n‚úÖ Synset resolution complete for {len(annotation_data)} task(s)!\")"
      ],
      "metadata": {
        "id": "RhnbdUWUVNra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "512f5a9b-efc6-4c8c-ceeb-8cce27142001"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Resolving synsets for all tasks...\n",
            "\n",
            "======================================================================\n",
            "\n",
            "üìå Task 1: 'invident' in \"existimat. haec qui gaudent, gaudeant perpetuo suo...\"\n",
            "----------------------------------------------------------------------\n",
            "   Found 4 unique synset(s):\n",
            "\n",
            "   üîπ 07565182-n\n",
            "      Lemmas: envy, enviousness\n",
            "      Definition: a feeling of grudging admiration and desire to have something that is possessed ...\n",
            "\n",
            "   üîπ 00759688-n\n",
            "      Lemmas: envy, invidia\n",
            "      Definition: spite and resentment at seeing the success of another (personified as one of the...\n",
            "\n",
            "   üîπ 01831561-v\n",
            "      Lemmas: envy\n",
            "      Definition: feel envious towards; admire enviously...\n",
            "\n",
            "   üîπ 01831006-v\n",
            "      Lemmas: envy, begrudge\n",
            "      Definition: be envious of; set one's heart on...\n",
            "\n",
            "\n",
            "üìå Task 2: '·ºêŒæŒ±Œ∫Œøœçœâ' in \"œÜœÅŒ≠ŒΩŒ±œÇ. œÄŒø·ø¶ œÄŒø·ø¶ Œ∫Œ±Œ∏ŒØŒ∂œâŒº º ·ºêŒΩ Œ∫Œ±Œª·ø∑, œÑ·ø∂ŒΩ ·ø•Œ∑œÑœåœÅœâŒΩ ·ºµŒΩ º ...\"\n",
            "----------------------------------------------------------------------\n",
            "   Found 6 unique synset(s):\n",
            "\n",
            "   üîπ 02174146-v\n",
            "      Lemmas: hear\n",
            "      Definition: perceive (sound) via the auditory sense...\n",
            "\n",
            "   üîπ 00600349-v\n",
            "      Lemmas: learn, hear, get word, get wind, pick up...\n",
            "      Definition: get to know or become aware of, usually accidentally...\n",
            "\n",
            "   üîπ 02506551-v\n",
            "      Lemmas: hear, try\n",
            "      Definition: examine or hear (evidence or a case) by judicial process...\n",
            "\n",
            "   üîπ 02111896-v\n",
            "      Lemmas: hear\n",
            "      Definition: receive a communication from someone...\n",
            "\n",
            "   üîπ 02175483-v\n",
            "      Lemmas: listen, hear, take heed\n",
            "      Definition: listen and pay attention...\n",
            "\n",
            "   üîπ 02193614-v\n",
            "      Lemmas: catch, take in, overhear\n",
            "      Definition: hear, usually without the knowledge of the speakers...\n",
            "\n",
            "\n",
            "üìå Task 3: 'praevidit' in \"et alte extulit: ille ictum venientem a vertice ve...\"\n",
            "----------------------------------------------------------------------\n",
            "   Found 4 unique synset(s):\n",
            "\n",
            "   üîπ 00722732-v\n",
            "      Lemmas: anticipate, previse, foreknow, foresee\n",
            "      Definition: realize beforehand...\n",
            "\n",
            "   üîπ 01639763-v\n",
            "      Lemmas: envision, foresee\n",
            "      Definition: picture to oneself; imagine possible...\n",
            "\n",
            "   üîπ 02571406-v\n",
            "      Lemmas: anticipate, foresee, forestall, counter\n",
            "      Definition: act in advance of; deal with ahead of time...\n",
            "\n",
            "   üîπ 02133754-v\n",
            "      Lemmas: see\n",
            "      Definition: perceive by sight or have the power to perceive by sight...\n",
            "\n",
            "\n",
            "üìå Task 4: '·ºêœÉŒπŒ¥Œµ·øñŒΩ' in \"œÄ·æ∑ œÄŒøœÑŒµ œÑ·ø∂ŒΩŒ¥Œµ œÄœåŒΩœâŒΩ œáœÅŒÆ œÉŒµ œÑŒ≠œÅŒºŒ± Œ∫Œ≠Œª - œÉŒ±ŒΩœÑ º ·ºêœÉŒπŒ¥Œµ...\"\n",
            "----------------------------------------------------------------------\n",
            "   Found 2 unique synset(s):\n",
            "\n",
            "   üîπ 02133754-v\n",
            "      Lemmas: see\n",
            "      Definition: perceive by sight or have the power to perceive by sight...\n",
            "\n",
            "   üîπ 00592510-v\n",
            "      Lemmas: understand, realize, realise, see\n",
            "      Definition: perceive (an idea or situation) mentally...\n",
            "\n",
            "======================================================================\n",
            "\n",
            "‚úÖ Synset resolution complete for 4 task(s)!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 6Ô∏è‚É£ Run Annotation\n",
        "\n",
        "Now we'll send each token + context to the language model, asking it to choose the most appropriate synset from the candidates.\n",
        "\n",
        "The model receives:\n",
        "- The token to disambiguate\n",
        "- The context sentence\n",
        "- A list of candidate synsets with their definitions\n",
        "\n",
        "It returns the synset ID it believes is correct."
      ],
      "metadata": {
        "id": "fUTKqQxWVO0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üöÄ Run Semantic Annotation { display-mode: \"form\" }\n",
        "\n",
        "import json\n",
        "import time\n",
        "\n",
        "def build_prompt(token, context, synsets_info):\n",
        "    \"\"\"Build the user prompt using the configured template.\"\"\"\n",
        "\n",
        "    synset_descriptions = []\n",
        "    for syn_id, info in synsets_info.items():\n",
        "        lemmas = ', '.join(info['lemmas'][:5])\n",
        "        synset_descriptions.append(\n",
        "            f\"- **{syn_id}**: {info['definition']} _(lemmas: {lemmas})_\"\n",
        "        )\n",
        "\n",
        "    synset_list = '\\n'.join(synset_descriptions)\n",
        "\n",
        "    # Fill in the template\n",
        "    prompt = PROMPT_CONFIG['user_template'].format(\n",
        "        token=token,\n",
        "        context=context,\n",
        "        synset_list=synset_list\n",
        "    )\n",
        "\n",
        "    return prompt\n",
        "\n",
        "\n",
        "def annotate_single(token, context, synsets_info, model_config):\n",
        "    \"\"\"Send a single annotation request to the API.\"\"\"\n",
        "\n",
        "    user_prompt = build_prompt(token, context, synsets_info)\n",
        "    synset_ids = list(synsets_info.keys())\n",
        "\n",
        "    try:\n",
        "        if model_config.get('use_responses_api', True):\n",
        "            # Use Responses API (OpenAI)\n",
        "            reasoning_config = None\n",
        "            if model_config['reasoning_effort'] != \"none\":\n",
        "                reasoning_config = {\"effort\": model_config['reasoning_effort']}\n",
        "\n",
        "            response = client.responses.create(\n",
        "                model=model_config['model'],\n",
        "                instructions=PROMPT_CONFIG['system'],\n",
        "                input=user_prompt,\n",
        "                reasoning=reasoning_config\n",
        "            )\n",
        "            result = response.output_text.strip()\n",
        "        else:\n",
        "            # Use Chat Completions API (compatible with most providers)\n",
        "            response = client.chat.completions.create(\n",
        "                model=model_config['model'],\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": PROMPT_CONFIG['system']},\n",
        "                    {\"role\": \"user\", \"content\": user_prompt}\n",
        "                ],\n",
        "                temperature=temperature  # Deterministic for annotation\n",
        "            )\n",
        "            result = response.choices[0].message.content.strip()\n",
        "\n",
        "        # Clean up the result (remove quotes, backticks, whitespace)\n",
        "        result = result.strip('`\"\\'').strip()\n",
        "\n",
        "        # Validate that result is one of the candidates\n",
        "        if result in synset_ids:\n",
        "            return result, \"success\", None\n",
        "        else:\n",
        "            # Try to find a partial match (model might have added extra text)\n",
        "            for syn_id in synset_ids:\n",
        "                if syn_id in result:\n",
        "                    return syn_id, \"partial_match\", f\"Extracted '{syn_id}' from '{result}'\"\n",
        "            return result, \"invalid\", f\"Response '{result}' not in candidates\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, \"error\", str(e)\n",
        "\n",
        "\n",
        "# Run annotation for all tasks\n",
        "print(\"üöÄ Starting annotation...\\n\")\n",
        "print(f\"   Provider: {API_CONFIG['provider']}\")\n",
        "print(f\"   Model: {MODEL_CONFIG['model']}\")\n",
        "print(f\"   API: {'Responses' if MODEL_CONFIG.get('use_responses_api', True) else 'Chat Completions'}\")\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "\n",
        "results = []\n",
        "\n",
        "for i, entry in enumerate(annotation_data, 1):\n",
        "    token = entry['token']\n",
        "    context = entry['context']\n",
        "    synsets = entry.get('resolved_synsets', {})\n",
        "\n",
        "    print(f\"\\nüìå Task {i}/{len(annotation_data)}: '{token}'\")\n",
        "    print(f\"   Context: \\\"{context[:60]}...\\\"\")\n",
        "    print(f\"   Candidates: {len(synsets)} synset(s)\")\n",
        "\n",
        "    if not synsets:\n",
        "        print(\"   ‚ö†Ô∏è Skipping ‚Äî no resolved synsets\")\n",
        "        results.append({\n",
        "            'token': token,\n",
        "            'context': context,\n",
        "            'predicted': None,\n",
        "            'status': 'skipped',\n",
        "            'message': 'No synsets resolved'\n",
        "        })\n",
        "        continue\n",
        "\n",
        "    # Call the API\n",
        "    predicted, status, message = annotate_single(token, context, synsets, MODEL_CONFIG)\n",
        "\n",
        "    result_entry = {\n",
        "        'token': token,\n",
        "        'context': context,\n",
        "        'num_candidates': len(synsets),\n",
        "        'candidates': list(synsets.keys()),\n",
        "        'predicted': predicted,\n",
        "        'status': status\n",
        "    }\n",
        "\n",
        "    if 'ground_truth' in entry:\n",
        "        result_entry['ground_truth'] = entry['ground_truth']\n",
        "        result_entry['correct'] = (predicted == entry['ground_truth'])\n",
        "\n",
        "    if message:\n",
        "        result_entry['message'] = message\n",
        "\n",
        "    results.append(result_entry)\n",
        "\n",
        "    # Display result\n",
        "    if status == \"success\":\n",
        "        print(f\"   ‚úÖ Predicted: {predicted}\")\n",
        "        if 'ground_truth' in entry:\n",
        "            if result_entry['correct']:\n",
        "                print(f\"   üéØ Correct! (ground truth: {entry['ground_truth']})\")\n",
        "            else:\n",
        "                print(f\"   ‚ùå Incorrect (ground truth: {entry['ground_truth']})\")\n",
        "    elif status == \"partial_match\":\n",
        "        print(f\"   ‚ö†Ô∏è Predicted: {predicted} ({message})\")\n",
        "    else:\n",
        "        print(f\"   ‚ùå Error: {message}\")\n",
        "\n",
        "    # Small delay to avoid rate limiting\n",
        "    time.sleep(0.5)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(f\"\\n‚úÖ Annotation complete! Processed {len(results)} task(s).\")\n",
        "\n",
        "# Store results globally\n",
        "annotation_results = results"
      ],
      "metadata": {
        "id": "zJ3cSoAsVQid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab1b596a-b5f5-4159-e42d-26bf5c663995"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting annotation...\n",
            "\n",
            "   Provider: DeepSeek\n",
            "   Model: deepseek-chat\n",
            "   API: Chat Completions\n",
            "\n",
            "======================================================================\n",
            "\n",
            "üìå Task 1/4: 'invident'\n",
            "   Context: \"existimat. haec qui gaudent, gaudeant perpetuo suo semper bo...\"\n",
            "   Candidates: 4 synset(s)\n",
            "   ‚úÖ Predicted: 01831561-v\n",
            "   üéØ Correct! (ground truth: 01831561-v)\n",
            "\n",
            "üìå Task 2/4: '·ºêŒæŒ±Œ∫Œøœçœâ'\n",
            "   Context: \"œÜœÅŒ≠ŒΩŒ±œÇ. œÄŒø·ø¶ œÄŒø·ø¶ Œ∫Œ±Œ∏ŒØŒ∂œâŒº º ·ºêŒΩ Œ∫Œ±Œª·ø∑, œÑ·ø∂ŒΩ ·ø•Œ∑œÑœåœÅœâŒΩ ·ºµŒΩ º ·ºêŒæŒ±Œ∫Œøœçœâ; œÉ...\"\n",
            "   Candidates: 6 synset(s)\n",
            "   ‚úÖ Predicted: 02175483-v\n",
            "   ‚ùå Incorrect (ground truth: 02193614-v)\n",
            "\n",
            "üìå Task 3/4: 'praevidit'\n",
            "   Context: \"et alte extulit: ille ictum venientem a vertice velox praevi...\"\n",
            "   Candidates: 4 synset(s)\n",
            "   ‚úÖ Predicted: 02133754-v\n",
            "   ‚ùå Incorrect (ground truth: 00722732-v)\n",
            "\n",
            "üìå Task 4/4: '·ºêœÉŒπŒ¥Œµ·øñŒΩ'\n",
            "   Context: \"œÄ·æ∑ œÄŒøœÑŒµ œÑ·ø∂ŒΩŒ¥Œµ œÄœåŒΩœâŒΩ œáœÅŒÆ œÉŒµ œÑŒ≠œÅŒºŒ± Œ∫Œ≠Œª - œÉŒ±ŒΩœÑ º ·ºêœÉŒπŒ¥Œµ·øñŒΩ ¬∑ ·ºÄŒ∫ŒØœáŒ∑...\"\n",
            "   Candidates: 2 synset(s)\n",
            "   ‚úÖ Predicted: 02133754-v\n",
            "   ‚ùå Incorrect (ground truth: 00592510-v)\n",
            "\n",
            "======================================================================\n",
            "\n",
            "‚úÖ Annotation complete! Processed 4 task(s).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 7Ô∏è‚É£ Results & Evaluation\n",
        "\n",
        "View your annotation results and evaluation metrics below."
      ],
      "metadata": {
        "id": "oDnKx_iZVRnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìä View Results { display-mode: \"form\" }\n",
        "\n",
        "print(\"üìä ANNOTATION RESULTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Display each result\n",
        "for i, result in enumerate(annotation_results, 1):\n",
        "    print(f\"\\nüìå Task {i}: '{result['token']}'\")\n",
        "    print(f\"   Context: {result['context'][:60]}...\")\n",
        "    print(f\"   Candidates: {result['num_candidates']} synset(s)\")\n",
        "    print(f\"   Predicted: {result.get('predicted', 'N/A')}\")\n",
        "\n",
        "    if 'ground_truth' in result:\n",
        "        status = \"‚úÖ CORRECT\" if result.get('correct') else \"‚ùå INCORRECT\"\n",
        "        print(f\"   Ground truth: {result['ground_truth']}\")\n",
        "        print(f\"   Status: {status}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "\n",
        "# Summary statistics\n",
        "total = len(annotation_results)\n",
        "successful = sum(1 for r in annotation_results if r['status'] == 'success')\n",
        "\n",
        "print(f\"\\nüìà SUMMARY:\")\n",
        "print(f\"   Total tasks: {total}\")\n",
        "print(f\"   Successfully annotated: {successful}\")\n",
        "print(f\"   Errors/skipped: {total - successful}\")"
      ],
      "metadata": {
        "id": "H1VjahIPVSc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "212bd6cc-af2c-4a4a-c730-ce5cab990b23"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä ANNOTATION RESULTS\n",
            "======================================================================\n",
            "\n",
            "üìå Task 1: 'invident'\n",
            "   Context: existimat. haec qui gaudent, gaudeant perpetuo suo semper bo...\n",
            "   Candidates: 4 synset(s)\n",
            "   Predicted: 01831561-v\n",
            "   Ground truth: 01831561-v\n",
            "   Status: ‚úÖ CORRECT\n",
            "\n",
            "üìå Task 2: '·ºêŒæŒ±Œ∫Œøœçœâ'\n",
            "   Context: œÜœÅŒ≠ŒΩŒ±œÇ. œÄŒø·ø¶ œÄŒø·ø¶ Œ∫Œ±Œ∏ŒØŒ∂œâŒº º ·ºêŒΩ Œ∫Œ±Œª·ø∑, œÑ·ø∂ŒΩ ·ø•Œ∑œÑœåœÅœâŒΩ ·ºµŒΩ º ·ºêŒæŒ±Œ∫Œøœçœâ; œÉ...\n",
            "   Candidates: 6 synset(s)\n",
            "   Predicted: 02175483-v\n",
            "   Ground truth: 02193614-v\n",
            "   Status: ‚ùå INCORRECT\n",
            "\n",
            "üìå Task 3: 'praevidit'\n",
            "   Context: et alte extulit: ille ictum venientem a vertice velox praevi...\n",
            "   Candidates: 4 synset(s)\n",
            "   Predicted: 02133754-v\n",
            "   Ground truth: 00722732-v\n",
            "   Status: ‚ùå INCORRECT\n",
            "\n",
            "üìå Task 4: '·ºêœÉŒπŒ¥Œµ·øñŒΩ'\n",
            "   Context: œÄ·æ∑ œÄŒøœÑŒµ œÑ·ø∂ŒΩŒ¥Œµ œÄœåŒΩœâŒΩ œáœÅŒÆ œÉŒµ œÑŒ≠œÅŒºŒ± Œ∫Œ≠Œª - œÉŒ±ŒΩœÑ º ·ºêœÉŒπŒ¥Œµ·øñŒΩ ¬∑ ·ºÄŒ∫ŒØœáŒ∑...\n",
            "   Candidates: 2 synset(s)\n",
            "   Predicted: 02133754-v\n",
            "   Ground truth: 00592510-v\n",
            "   Status: ‚ùå INCORRECT\n",
            "\n",
            "======================================================================\n",
            "\n",
            "üìà SUMMARY:\n",
            "   Total tasks: 4\n",
            "   Successfully annotated: 4\n",
            "   Errors/skipped: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìè Evaluation Metrics { display-mode: \"form\" }\n",
        "#@markdown This cell calculates accuracy if ground truth labels were provided.\n",
        "\n",
        "# Check if we have ground truth\n",
        "has_ground_truth = any('ground_truth' in r for r in annotation_results)\n",
        "\n",
        "if not has_ground_truth:\n",
        "    print(\"‚ÑπÔ∏è No ground truth labels provided ‚Äî skipping evaluation.\")\n",
        "else:\n",
        "    print(\"üìè EVALUATION METRICS\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Filter to only tasks with ground truth\n",
        "    eval_tasks = [r for r in annotation_results if 'ground_truth' in r and r['status'] == 'success']\n",
        "\n",
        "    if not eval_tasks:\n",
        "        print(\"‚ö†Ô∏è No successfully annotated tasks with ground truth.\")\n",
        "    else:\n",
        "        # Calculate accuracy\n",
        "        correct = sum(1 for r in eval_tasks if r.get('correct', False))\n",
        "        total = len(eval_tasks)\n",
        "        accuracy = correct / total * 100\n",
        "\n",
        "        print(f\"\\nüéØ ACCURACY: {correct}/{total} = {accuracy:.1f}%\")\n",
        "\n",
        "        # Calculate average number of candidates (for context)\n",
        "        avg_candidates = sum(r['num_candidates'] for r in eval_tasks) / len(eval_tasks)\n",
        "        random_baseline = 100 / avg_candidates\n",
        "\n",
        "        print(f\"\\nüìä CONTEXT:\")\n",
        "        print(f\"   Average candidates per task: {avg_candidates:.1f}\")\n",
        "        print(f\"   Random baseline accuracy: {random_baseline:.1f}%\")\n",
        "        print(f\"   Improvement over random: {accuracy - random_baseline:+.1f} percentage points\")\n",
        "\n",
        "        # Breakdown by number of candidates\n",
        "        print(f\"\\nüìã BREAKDOWN BY DIFFICULTY:\")\n",
        "\n",
        "        from collections import defaultdict\n",
        "        by_num_candidates = defaultdict(list)\n",
        "        for r in eval_tasks:\n",
        "            by_num_candidates[r['num_candidates']].append(r.get('correct', False))\n",
        "\n",
        "        for num_cands in sorted(by_num_candidates.keys()):\n",
        "            tasks = by_num_candidates[num_cands]\n",
        "            acc = sum(tasks) / len(tasks) * 100\n",
        "            print(f\"   {num_cands} candidates: {sum(tasks)}/{len(tasks)} correct ({acc:.1f}%)\")\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 70)"
      ],
      "metadata": {
        "id": "bRzCki3nVTZP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37fac06e-c771-4e79-a129-bdbbd82f14c7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìè EVALUATION METRICS\n",
            "======================================================================\n",
            "\n",
            "üéØ ACCURACY: 1/4 = 25.0%\n",
            "\n",
            "üìä CONTEXT:\n",
            "   Average candidates per task: 4.0\n",
            "   Random baseline accuracy: 25.0%\n",
            "   Improvement over random: +0.0 percentage points\n",
            "\n",
            "üìã BREAKDOWN BY DIFFICULTY:\n",
            "   2 candidates: 0/1 correct (0.0%)\n",
            "   4 candidates: 1/2 correct (50.0%)\n",
            "   6 candidates: 0/1 correct (0.0%)\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 8Ô∏è‚É£ Export Results\n",
        "\n",
        "Download your annotation results as JSON or CSV."
      ],
      "metadata": {
        "id": "mILqRc_yVUeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üíæ Export Results { display-mode: \"form\" }\n",
        "\n",
        "export_format = \"CSV\" #@param [\"JSON\", \"CSV\"]\n",
        "\n",
        "from google.colab import files\n",
        "import json\n",
        "import csv\n",
        "import io\n",
        "\n",
        "if export_format == \"JSON\":\n",
        "    # Export as JSON\n",
        "    filename = \"annotation_results.json\"\n",
        "    content = json.dumps(annotation_results, indent=2, ensure_ascii=False)\n",
        "\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        f.write(content)\n",
        "\n",
        "    print(f\"üìÑ JSON Preview:\\n\")\n",
        "    print(content[:500] + \"...\" if len(content) > 500 else content)\n",
        "\n",
        "else:\n",
        "    # Export as CSV\n",
        "    filename = \"annotation_results.csv\"\n",
        "\n",
        "    fieldnames = ['token', 'context', 'num_candidates', 'predicted', 'ground_truth', 'correct', 'status']\n",
        "\n",
        "    output = io.StringIO()\n",
        "    writer = csv.DictWriter(output, fieldnames=fieldnames, extrasaction='ignore')\n",
        "    writer.writeheader()\n",
        "    for result in annotation_results:\n",
        "        writer.writerow(result)\n",
        "\n",
        "    content = output.getvalue()\n",
        "\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        f.write(content)\n",
        "\n",
        "    print(f\"üìÑ CSV Preview:\\n\")\n",
        "    print(content[:500] + \"...\" if len(content) > 500 else content)\n",
        "\n",
        "print(f\"\\n\" + \"=\" * 70)\n",
        "print(f\"\\n‚¨áÔ∏è Downloading {filename}...\")\n",
        "files.download(filename)"
      ],
      "metadata": {
        "id": "DnaKlBraVVVr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "13e4125e-f236-4290-c058-9339436906a6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÑ CSV Preview:\n",
            "\n",
            "token,context,num_candidates,predicted,ground_truth,correct,status\r\n",
            "invident,\"existimat. haec qui gaudent, gaudeant perpetuo suo semper bono; qui invident, ne umquam eorum quisquam invideat prosus commodis. Age accumbe\",4,01831561-v,01831561-v,True,success\r\n",
            "·ºêŒæŒ±Œ∫Œøœçœâ,\"œÜœÅŒ≠ŒΩŒ±œÇ. œÄŒø·ø¶ œÄŒø·ø¶ Œ∫Œ±Œ∏ŒØŒ∂œâŒº º ·ºêŒΩ Œ∫Œ±Œª·ø∑, œÑ·ø∂ŒΩ ·ø•Œ∑œÑœåœÅœâŒΩ ·ºµŒΩ º ·ºêŒæŒ±Œ∫Œøœçœâ; œÉ·Ω∫ Œ¥ º ·ºÑœÄŒπŒ∏ º ·Ω¶ ŒòœÅ·æ∑œÑœÑ º ·ºêŒ∫œÄŒøŒ¥œéŒΩ. Œ¥ŒøœçŒªŒøŒπœÇ Œ≥·Ω∞œÅ Œø·ΩêŒ∫\",6,02175483-v,02193614-v,False,success\r\n",
            "praevidit,\"et alte extulit: ille ictum venientem a vertice velox praevidit, celerique el...\n",
            "\n",
            "======================================================================\n",
            "\n",
            "‚¨áÔ∏è Downloading annotation_results.csv...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_08a47645-4c5d-4e1f-865d-72b93b165de5\", \"annotation_results.csv\", 968)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## üìé Appendix: Download Templates\n",
        "\n",
        "Run the cells below to download blank templates for CSV or JSON input."
      ],
      "metadata": {
        "id": "CHhzILWzVWRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üì• Download CSV Template { display-mode: \"form\" }\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "csv_template = \"\"\"token,context,candidates,ground_truth\n",
        "bank,\"I deposited money at the bank this morning.\",\"bank, financial_institution, shore\",08420278-n\n",
        "bank,\"We had a picnic on the river bank.\",\"bank, shore, slope\",09213565-n\n",
        "bright,\"She is a bright student.\",\"bright, intelligent, luminous\",\n",
        "\"\"\"\n",
        "\n",
        "with open('annotation_template.csv', 'w') as f:\n",
        "    f.write(csv_template)\n",
        "\n",
        "print(\"üìÑ CSV Template Preview:\")\n",
        "print(\"-\" * 50)\n",
        "print(csv_template)\n",
        "print(\"-\" * 50)\n",
        "print(\"\\n‚¨áÔ∏è Downloading template...\")\n",
        "files.download('annotation_template.csv')"
      ],
      "metadata": {
        "id": "ELlNuHY5VXQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üì• Download JSON Template { display-mode: \"form\" }\n",
        "\n",
        "from google.colab import files\n",
        "import json\n",
        "\n",
        "json_template = [\n",
        "    {\n",
        "        \"token\": \"bank\",\n",
        "        \"context\": \"I deposited money at the bank this morning.\",\n",
        "        \"candidates\": [\"bank\", \"financial_institution\", \"shore\", \"08420278-n\"],\n",
        "        \"ground_truth\": \"08420278-n\"\n",
        "    },\n",
        "    {\n",
        "        \"token\": \"bank\",\n",
        "        \"context\": \"We had a picnic on the river bank.\",\n",
        "        \"candidates\": [\"bank\", \"shore\", \"slope\"],\n",
        "        \"ground_truth\": \"09213565-n\"\n",
        "    },\n",
        "    {\n",
        "        \"token\": \"bright\",\n",
        "        \"context\": \"She is a bright student who excels in mathematics.\",\n",
        "        \"candidates\": [\"bright\", \"intelligent\", \"luminous\", \"shining\"]\n",
        "    }\n",
        "]\n",
        "\n",
        "content = json.dumps(json_template, indent=2)\n",
        "\n",
        "with open('annotation_template.json', 'w') as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"üìÑ JSON Template Preview:\")\n",
        "print(\"-\" * 50)\n",
        "print(content)\n",
        "print(\"-\" * 50)\n",
        "print(\"\\n‚¨áÔ∏è Downloading template...\")\n",
        "files.download('annotation_template.json')"
      ],
      "metadata": {
        "id": "_VdmAkgRVYi4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}